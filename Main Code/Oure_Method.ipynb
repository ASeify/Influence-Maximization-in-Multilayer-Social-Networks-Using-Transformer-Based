{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "GKcIHTZK0QrQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_PATH = os.path.dirname(os.path.abspath('../Classes/'))\n",
    "if not (CLASSES_PATH in sys.path):\n",
    "    sys.path.append(CLASSES_PATH)\n",
    "from Classes.Files_Handler_Class import Files_Handler\n",
    "from Classes.K_Shell_Calculate_Class import K_Shell_Calculate\n",
    "from Classes.Resd_Network_Infos_Class import Resd_Network_Infos\n",
    "from Classes.SIR_Diffusion_Model_Class import SIR_Diffusion_Model\n",
    "from Classes.Get_Past_Results_Class import Get_Past_Results\n",
    "from Classes.Network_Infos_Writer_Class import Network_Infos_Writer\n",
    "from Classes.Layers_Ranking_Class_Old import Layers_Ranking\n",
    "from Classes.Network_Node_Centrality_Class_Old import Network_Node_Centrality\n",
    "from Classes.Bcolors_Class import Bcolors as bcolors\n",
    "from Classes.CSV_Files_Class import CSV_Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed_set_size = 5\n",
    "version_num = 'v02'\n",
    "\n",
    "color_list = [\"light_red\", \"light_green\", \"light_yellow\",\n",
    "               \"light_blue\",\"light_magenta\", \"light_cyan\",\n",
    "               \"blue\", \"red\", \"white\", \"green\", \"yellow\",\n",
    "                 \"magenta\", \"cyan\", ]\n",
    "tqdm_color_list = ['blue', 'red', 'green', 'cyan', 'magenta', 'yellow', 'black', 'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_centrality = ['layer_density','layer_degree_histogram','layer_edge_weight',\n",
    "                    'layer_sombor_index', 'layer_nodes_weight','layer_k_shell_weight']\n",
    "node_centrality = ['degree', 'clustering', 'nip', 'sombor_index', 'ego_density','ego_degree',\n",
    "                     'ego_k_shell', 'ego_degree_mean','kss', 'vote_power']\n",
    "drop_centrality = ['layer_id', 'node_id', 'weight', 'k_shell', 'k_shell_itr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "1fwFbjlz0QrT"
   },
   "outputs": [],
   "source": [
    "source_code_path = str(os.getcwd())\n",
    "source_code_path = source_code_path.replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5pZ-tpz0QrT",
    "outputId": "87bd3c86-0b78-48bc-9997-7baed3af6c55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'D:/Masters thesis/Methods For Compare/Temp/12 - realitycommons (84 Node and 5 Layer)/',\n",
       " 'name': 'Relationshipsfromsurveys',\n",
       " 'type': '.edgelist'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files_obj = CSV_Files()\n",
    "files_handler_obj = Files_Handler()\n",
    "file_path = files_handler_obj.select_files(\"text files\", \".edgeslist .edgelist .edges .mtx .txt\", 'Select Dataset')\n",
    "if file_path is None or file_path == '':\n",
    "    sys.exit(\"File Selection Canceled !\")\n",
    "file_info = files_handler_obj.get_file_path_info(file_path)\n",
    "network_name = file_info['name']\n",
    "network_type = file_info['type']\n",
    "network_path = file_info['path']\n",
    "if network_name == \"\":\n",
    "    sys.exit(\"Dont Network Selection!\")\n",
    "file_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "GsCNPeaQ0QrU"
   },
   "outputs": [],
   "source": [
    "resd_network_infos_object = Resd_Network_Infos()\n",
    "(\n",
    "    network_layers_info,\n",
    "    network_layers_nodes,\n",
    "    entra_layer_edges,\n",
    "    entra_layer_edges_features,\n",
    "    inter_layer_edge,\n",
    ") = Resd_Network_Infos.read_nodeFrom_layerFrom_nodeTo_layerTo(\n",
    "    network_path, network_name, network_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr2Arb-X0QrU",
    "outputId": "e8e8fb99-407d-418a-b7c9-3f6576ff0902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationshipsfromsurveys \n",
      "\n",
      "\u001b[92mLayer 1: 82 Node And 620 Edge\u001b[0m\n",
      "\u001b[93mLayer 2: 84 Node And 1327 Edge\u001b[0m\n",
      "\u001b[94mLayer 3: 84 Node And 1237 Edge\u001b[0m\n",
      "\u001b[95mLayer 4: 83 Node And 2132 Edge\u001b[0m\n",
      "\u001b[96mLayer 5: 83 Node And 1956 Edge\u001b[0m\n",
      "\n",
      "network entier nodes : \u001b[33m84\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(file_info['name'], '\\n')\n",
    "layers_id = []\n",
    "network_layers_count = len(network_layers_info)\n",
    "graphs_of_network = [None] * network_layers_count\n",
    "network_entier_edges = \"\"\n",
    "layers_nodes_infect_scale = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "while i < network_layers_count:\n",
    "    graphs_of_network[i] = nx.Graph()\n",
    "    network_layers_nodes[i] = list(set(network_layers_nodes[i]))\n",
    "    layers_nodes_infect_scale.append({})\n",
    "    if len(network_layers_nodes[i]) > 0:\n",
    "        graphs_of_network[i].add_edges_from(entra_layer_edges[i])\n",
    "\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"degree\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"k_shell\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"k_shell_itr\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"nip\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"sombor_index\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"ego_density\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"ego_degree\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"ego_k_shell\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"ego_degree_mean\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"kss\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], 1, \"vote_power\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"clustering\")\n",
    "        nx.set_node_attributes(graphs_of_network[i], None, \"SIR\")\n",
    "        \n",
    "        graphs_of_network[i].graph[\"id\"] = i\n",
    "        graphs_of_network[i].graph[\"layer_density\"] = nx.density(graphs_of_network[i])\n",
    "        graphs_of_network[i].graph[\"layer_degree_histogram\"] = None\n",
    "        graphs_of_network[i].graph[\"layer_edge_weight\"] = None\n",
    "        graphs_of_network[i].graph[\"layer_sombor_index\"] = None\n",
    "        graphs_of_network[i].graph[\"layer_nodes_weight\"] = None\n",
    "        graphs_of_network[i].graph[\"layer_k_shell_weight\"] = None\n",
    "\n",
    "        K_Shell_Calculate_Object = K_Shell_Calculate(graphs_of_network[i])\n",
    "        graphs_of_network[i] = K_Shell_Calculate_Object.get_k_shell_info()\n",
    "        del K_Shell_Calculate_Object\n",
    "        degrees = dict(graphs_of_network[i].degree())\n",
    "        nx.set_node_attributes(graphs_of_network[i], degrees, \"degree\")\n",
    "        layers_id.append(str(i))\n",
    "        print(colored(\"Layer \"  + str(i) + \": \" + str(graphs_of_network[i].number_of_nodes()) + \" Node And \" +\n",
    "                       str(graphs_of_network[i].number_of_edges()) + \" Edge\", color_list[j]))\n",
    "        # print(colored(graphs_of_network[i].graph['k_shell_info'], color_list[i]))\n",
    "    i += 1\n",
    "    j += 1\n",
    "    if j >= len(color_list):\n",
    "        j = 0\n",
    "\n",
    "network_entier_nodes_list = []\n",
    "for item in network_layers_nodes:\n",
    "    network_entier_nodes_list += item\n",
    "\n",
    "network_entier_nodes_list = list(set(network_entier_nodes_list))\n",
    "network_entier_nodes_count = len(network_entier_nodes_list)\n",
    "print()\n",
    "print(\"network entier nodes : \" + colored(str(network_entier_nodes_count), \"yellow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_past_results_obj = Get_Past_Results(network_path, network_name)\n",
    "network_infos_writer_object = Network_Infos_Writer(network_path, network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_path = files_handler_obj.make_dir(file_info['path'], 'Our Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "Me7kYlpD0QrV"
   },
   "outputs": [],
   "source": [
    "del network_layers_nodes, entra_layer_edges\n",
    "del entra_layer_edges_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bx8E343H0QrX",
    "outputId": "1695a6a2-2286-493c-d62d-3c71ef611ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationshipsfromsurveys\n",
      "Load layer results:  \u001b[95m\u001b[92mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(network_name)\n",
    "layer_past_result_status = False\n",
    "layer_past_result_status = get_past_results_obj.get_past_layer_att_results(graphs_of_network)\n",
    "if layer_past_result_status:\n",
    "        print(\"Load layer results: \", bcolors.HEADER + bcolors.OKGREEN + str(layer_past_result_status) + bcolors.ENDC)\n",
    "else:\n",
    "        print(\"Load layer results: \", bcolors.HEADER + bcolors.FAIL + str(layer_past_result_status) + bcolors.ENDC)\n",
    "if not layer_past_result_status:\n",
    "        layers_ranking_object = Layers_Ranking()\n",
    "        print(bcolors.HEADER + bcolors.OKBLUE + 'Calc layer layers_density_weight' + bcolors.ENDC)\n",
    "        layers_ranking_object.layers_density_weight(graphs_of_network)\n",
    "        print(bcolors.HEADER + bcolors.OKBLUE + '\\nCalc layer layers_degree_distribution' + bcolors.ENDC)\n",
    "        layers_ranking_object.layers_degree_distribution(graphs_of_network)\n",
    "        print(bcolors.HEADER + bcolors.OKBLUE + '\\nCalc layer layers_edges_and_sombor_index' + bcolors.ENDC)\n",
    "        layers_ranking_object.layers_edges_and_sombor_index(graphs_of_network)\n",
    "        print(bcolors.HEADER + bcolors.OKBLUE + '\\nCalc layer layers_nodes_weight' + bcolors.ENDC)\n",
    "        layers_ranking_object.layers_nodes_weight(graphs_of_network)\n",
    "        print(bcolors.HEADER + bcolors.OKBLUE + '\\nCalc layer layers_k_shell_weight' + bcolors.ENDC)\n",
    "        layers_ranking_object.layers_k_shell_weight(graphs_of_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not layer_past_result_status:\n",
    "    network_infos_writer_object.write_network_layer_infos_csv(graphs_of_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20A79kSa0QrX",
    "outputId": "6a83a10a-beda-4d20-f3be-1952752a330f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "past_node_att_file = get_past_results_obj.get_past_node_att_file()\n",
    "if past_node_att_file != False:\n",
    "    node_past_result_att_status = float(past_node_att_file.split('/')[-1].split(' ')[-2].split('=')[-1])\n",
    "else:\n",
    "    node_past_result_att_status = 0\n",
    "print(node_past_result_att_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BbToPeE0QrX",
    "outputId": "e18e9b79-8d6c-4f61-b231-9d6ec594e3b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer\t density\t degree_histogram\t edge_weight\t sombor_index\t nodes_weight\t k_shell_weight\n",
      "\u001b[92m1 \t 0.1866908 \t 15.1219512 \t\t 0.0062000 \t 3.3709498 \t 0.0082000 \t 30.5788569\u001b[0m\n",
      "\u001b[93m2 \t 0.3806655 \t 31.5952381 \t\t 0.0132700 \t 5.4945591 \t 0.0084000 \t 54.1307046\u001b[0m\n",
      "\u001b[94m3 \t 0.3548480 \t 29.4523810 \t\t 0.0123700 \t 5.1603057 \t 0.0084000 \t 83.0354331\u001b[0m\n",
      "\u001b[95m4 \t 0.6265060 \t 51.3734940 \t\t 0.0213200 \t 7.8326236 \t 0.0083000 \t 171.7824985\u001b[0m\n",
      "\u001b[96m5 \t 0.5747870 \t 47.1325301 \t\t 0.0195600 \t 7.4284391 \t 0.0083000 \t 240.3359174\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Layer\\t density\\t degree_histogram\\t edge_weight\\t sombor_index\\t nodes_weight\\t k_shell_weight')\n",
    "f_p = '{:9.7f}' # float padding\n",
    "c = 0\n",
    "for i, graph in enumerate(graphs_of_network):\n",
    "    if graph.number_of_nodes() > 0:\n",
    "        print(colored((str(i)+ ' \\t ' + str(f_p.format(graph.graph[\"layer_density\"]))+ ' \\t ' +\n",
    "                       str(f_p.format(graph.graph[\"layer_degree_histogram\"]))+ ' \\t\\t ' +\n",
    "                       str(f_p.format(graph.graph[\"layer_edge_weight\"]))+ ' \\t ' +\n",
    "                       str(f_p.format(graph.graph[\"layer_sombor_index\"]))+ ' \\t ' +\n",
    "                       str(f_p.format(graph.graph[\"layer_nodes_weight\"]))+ ' \\t ' +\n",
    "                       str(f_p.format(graph.graph[\"layer_k_shell_weight\"]))),\n",
    "                       color_list[c]))\n",
    "    c += 1\n",
    "    if c >= len(color_list):\n",
    "        c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "f08KHwph0QrZ",
    "outputId": "8f4f8424-a883-4d76-cf86-b56d34288523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationshipsfromsurveys\n",
      "\n",
      "Load temp results:  \u001b[95m\u001b[92mTrue\u001b[0m\n",
      "Load temp results count:  \u001b[95m\u001b[92m84\u001b[0m \n",
      "\n",
      "\n",
      "Layer 1: Graph with 82 nodes and 620 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 82/82 [00:00<00:00, 82084.23 Node/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 2: Graph with 84 nodes and 1327 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[31m██████████\u001b[0m| 84/84 [00:00<00:00, 83986.06 Node/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 3: Graph with 84 nodes and 1237 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 84/84 [00:00<?, ? Node/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 4: Graph with 83 nodes and 2132 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|\u001b[36m██████████\u001b[0m| 83/83 [00:00<00:00, 83144.79 Node/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 5: Graph with 83 nodes and 1956 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[35m██████████\u001b[0m| 83/83 [00:00<?, ? Node/s]\n"
     ]
    }
   ],
   "source": [
    "print(network_name)\n",
    "# past_results_status = False\n",
    "past_results_status, past_results_nodes = get_past_results_obj.get_past_node_att_results(graphs_of_network)\n",
    "if past_results_status:\n",
    "    print(\"\\nLoad temp results: \", bcolors.HEADER + bcolors.OKGREEN + str(past_results_status) + bcolors.ENDC)\n",
    "    print(\"Load temp results count: \", bcolors.HEADER + bcolors.OKGREEN + str(len(past_results_nodes)) + bcolors.ENDC, '\\n')\n",
    "else:\n",
    "    print(\"Load temp results: \", bcolors.HEADER + bcolors.FAIL + str(past_results_status) + bcolors.ENDC, '\\n')\n",
    "Network_Node_Centrality_obj = Network_Node_Centrality()\n",
    "hop_num = 2\n",
    "Network_Node_Centrality_obj.get_nodes_centrality(network_infos_writer_object, graphs_of_network, None, hop=hop_num)\n",
    "network_infos_writer_object.write_network_nodes_info_csv(1, graphs_of_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nzFGXKrg0QrZ",
    "outputId": "4faa0706-759f-4316-bc8e-2eac14dc9e31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HIabTV9t0QrZ"
   },
   "outputs": [],
   "source": [
    "class Multilayer_Full_Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, node_in_features: int, node_out_features: int,\n",
    "        layer_in_features: int, layer_out_features: int,\n",
    "        encoder_head: int, num_encoder:int, encoder_activation: str,\n",
    "        bias: bool, dropout: float,\n",
    "        activation: nn.modules.activation, device: str = \"cpu\",\n",
    "        h0:int = 8, h1: int = 16, h2: int = 32, h3: int = 64, h4: int = 128, h5 = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.node_embeding = nn.Sequential(\n",
    "            nn.Linear(in_features=node_in_features, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=node_out_features, bias=bias, device=device)\n",
    "        )\n",
    "        self.layer_embeding = nn.Sequential(\n",
    "            nn.Linear(in_features=layer_in_features, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=node_out_features, bias=bias, device=device)\n",
    "            )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=node_out_features, nhead=encoder_head,\n",
    "                dim_feedforward=(4 * node_out_features), dropout=dropout,\n",
    "                activation=encoder_activation, bias=bias,\n",
    "                batch_first=True, device=device),\n",
    "            num_encoder)\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(in_features=node_out_features, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h0, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h0, out_features=1, bias=bias, device=device),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, node_x, layer_x):\n",
    "        node_y = self.node_embeding(node_x).unsqueeze(dim=2)\n",
    "        layer_y = self.layer_embeding(layer_x).unsqueeze(dim=1)\n",
    "        y = torch.matmul(node_y, layer_y)\n",
    "        y = self.encoder(y)\n",
    "        y = torch.mean(y, dim=1)\n",
    "        y = self.regression(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HNUKSzG90QrZ",
    "outputId": "d6d66689-bf5c-472f-f4df-695c6dbc04b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best_loss_valid model lr=0.0001 wd=1e-05 epochs=825  loss_valid=2.8144 loss_train=2.8536.pt'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = ''\n",
    "files_names = files_handler_obj.get_files_in_path(source_code_path)\n",
    "for item in files_names:\n",
    "    if item.split('.')[-1] == 'pt':\n",
    "        model_file = item\n",
    "        break\n",
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2iuRsE-Q0Qra",
    "outputId": "bbb0e09c-605e-425c-8cb3-37fddf2867a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mModel load\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_path = source_code_path + '/' +model_file\n",
    "model = None\n",
    "try:\n",
    "    model = torch.load(model_path, weights_only= False, map_location=torch.device(device))\n",
    "    torch.set_grad_enabled(False)\n",
    "    print(bcolors.OKGREEN + 'Model load' + bcolors.ENDC)\n",
    "except Exception as e:\n",
    "    print(bcolors.FAIL + 'Model not found!' + bcolors.ENDC)\n",
    "    sys.exit(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lq6Aeq230Qra",
    "outputId": "b44d844c-d57b-4242-ccd7-d8f8adf881d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "network_nodes_list_SIR_p = {}\n",
    "nodes_SIR_p = defaultdict(dict)\n",
    "SIR_p_file_status = False\n",
    "SIR_p_file = file_info['path'] + file_info['name'] + ' SIR_p/' + file_info['name'] + ' SIR_p.csv'\n",
    "try:\n",
    "    with open(SIR_p_file) as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        network_nodes_list_SIR_p = dict(reader)\n",
    "    SIR_p_file_status = True\n",
    "except:\n",
    "    SIR_p_file_status = False\n",
    "\n",
    "nodes_SIR_p_file_status = False\n",
    "nodes_SIR_p_file = file_info['path'] + file_info['name'] + ' SIR_p/' + file_info['name'] + ' temp SIR_p.csv'\n",
    "try:\n",
    "    nodes_SIR_p = pd.read_csv(nodes_SIR_p_file, index_col=0)\n",
    "    nodes_SIR_p = pd.DataFrame.to_dict(nodes_SIR_p, orient=\"index\")\n",
    "    nodes_SIR_p_file_status = True\n",
    "except Exception as e:\n",
    "    nodes_SIR_p_file_status = False\n",
    "\n",
    "print(SIR_p_file_status, nodes_SIR_p_file_status)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Mf05DE8Q0Qrb"
   },
   "outputs": [],
   "source": [
    "if nodes_SIR_p_file_status:\n",
    "    for graph in graphs_of_network:\n",
    "        if graph.number_of_nodes() > 0 and graph.number_of_edges() > 0:\n",
    "            nx.set_node_attributes(graph, None, \"SIR_p\")\n",
    "    for node in network_entier_nodes_list:\n",
    "        node_SIR_p_values = nodes_SIR_p[int(node)]\n",
    "        for k, v in node_SIR_p_values.items():\n",
    "            if k != 'AVG':\n",
    "                if node in graphs_of_network[int(k)].nodes():\n",
    "                    graphs_of_network[int(k)].nodes[node]['SIR_p']= float(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rKVk4vc_0Qra"
   },
   "outputs": [],
   "source": [
    "def get_model_outputs(model, node_data_loader:DataLoader, layer_data:torch.Tensor, device):\n",
    "  model.eval()\n",
    "  outputs = []\n",
    "  with tqdm(node_data_loader, unit=\" batch\") as tepoch:\n",
    "    with torch.no_grad():\n",
    "      for i, (node_inputs, _) in enumerate(tepoch):\n",
    "        tepoch.set_description(f\"Batch {i + 1}\")\n",
    "        node_inputs = node_inputs.to(device)\n",
    "        layer_inputs = layer_data.to(device)\n",
    "        outputs += (((model(node_inputs, layer_inputs)).squeeze(dim=1)).tolist())\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_mu = torch.FloatTensor([ 26.0719,   0.1327,  19.4767,  12.0195,   3.8776, -14.1054, -18.9498, 31.2976,   2.8534,   8.7193])\n",
    "node_std = torch.FloatTensor([ 78.4243,   0.2285,  89.8148,  50.2024,  27.2598,  81.4585, 189.8591, 115.6929,  10.7834,  60.4080])\n",
    "\n",
    "layer_mu = torch.FloatTensor([3.6536e-03, 1.9344e+01, 4.9918e+04, 2.9013e+02, 3.5260e+04, 6.3725e+01])\n",
    "layer_std = torch.FloatTensor([2.1411e-02, 2.6726e+01, 1.4293e+05, 1.3756e+03, 9.9566e+04, 1.5917e+02])\n",
    "\n",
    "node_scale_vector = torch.FloatTensor([10000, 1000000, 1000000000, 100000, 1000000000, 1000000000, 1000000, 100000, 10000, 1])\n",
    "layer_scale_vector = torch.FloatTensor([1, 10, 10, 100, 1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_sir = []\n",
    "model_sir = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6WZZIkvV0Qrb",
    "outputId": "c3a34cc4-4b81-4b90-c7c2-af9e3a906154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "Done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "layers_counter = len(graphs_of_network)\n",
    "if not nodes_SIR_p_file_status and len(network_entier_nodes_list) != len(network_nodes_list_SIR_p.keys()):\n",
    "    tqdm_color_index = 0\n",
    "    for graph in graphs_of_network:\n",
    "        if graph.number_of_nodes() > 0 and graph.number_of_edges() > 0:\n",
    "            degrees = dict(graph.degree())  # Get the degree of each node\n",
    "            mean_degree = sum(degrees.values()) / len(degrees)\n",
    "            print(bcolors.FAIL + f'\\nlayer {layers_counter}: {graph}' + bcolors.ENDC)\n",
    "            real_sir.append([])\n",
    "            model_sir.append([])\n",
    "        # ---------- Extract layer features ---------------------\n",
    "            layer_x_data = []\n",
    "            layer_info = graph.graph\n",
    "            layer_id = layer_info['id']\n",
    "            for k, v in layer_info.items():\n",
    "                if (k in layer_centrality):\n",
    "                        layer_x_data.append(v)\n",
    "            \n",
    "            layer_x_data = torch.FloatTensor(layer_x_data)\n",
    "            layer_x_data = layer_x_data / layer_scale_vector\n",
    "            layer_x_data = (layer_x_data - layer_mu) / layer_std\n",
    "            layer_x_data = layer_x_data.to(device)\n",
    "        # -------------------------------------------------------\n",
    "        # ---------- Extract nodes features ---------------------\n",
    "            nodes_list = list(graph.nodes())\n",
    "            with tqdm(nodes_list, unit=\" Node\") as tepoch:\n",
    "                if tqdm_color_index >= len(tqdm_color_list):\n",
    "                    tqdm_color_index = 0\n",
    "                tepoch.colour = tqdm_color_list[tqdm_color_index]\n",
    "                tqdm_color_index += 1\n",
    "                for i, node in enumerate(tepoch):\n",
    "                    tepoch.set_description(f\"Node {i + 1}\")\n",
    "                    node_x_data = []\n",
    "                    node_info = graph.nodes[node]\n",
    "                    for centrality in node_centrality:\n",
    "                        node_x_data.append(float(node_info[centrality]))\n",
    "            # -------------------------------------------------------\n",
    "                    node_x_data = torch.FloatTensor(node_x_data)\n",
    "                    node_x_data = node_x_data / node_scale_vector\n",
    "                    node_x_data = (node_x_data - node_mu) / node_std\n",
    "                    node_x_data = node_x_data.to(device)\n",
    "                # -----Feeding data to neural network and get outputs----\n",
    "                    with torch.no_grad():\n",
    "                        output = model(node_x_data.unsqueeze(0), layer_x_data.unsqueeze(0)).squeeze(1).tolist()[0]\n",
    "                    \n",
    "                    output = output * (graphs_of_network[layer_id].degree(node) / mean_degree)\n",
    "                    graphs_of_network[layer_id].nodes[node][\"SIR_p\"] = output\n",
    "                    nodes_SIR_p[node][layer_id] = output\n",
    "                    real_sir[-1].append(graphs_of_network[layer_id].nodes[node][\"SIR\"])\n",
    "                    model_sir[-1].append(output)\n",
    "        # -------------------------------------------------------\n",
    "        layers_counter -= 1\n",
    "else:\n",
    "    for graph in graphs_of_network:\n",
    "        if graph.number_of_nodes() > 0 and graph.number_of_edges() > 0:\n",
    "            real_sir.append([])\n",
    "            model_sir.append([])\n",
    "            layer_id = graph.graph['id']\n",
    "            nodes_list = list(graph.nodes())\n",
    "            for node in nodes_list:\n",
    "                if not(graphs_of_network[layer_id].nodes[node][\"SIR\"] is None):\n",
    "                    real_sir[-1].append(graphs_of_network[layer_id].nodes[node][\"SIR\"])\n",
    "                    model_sir[-1].append(graphs_of_network[layer_id].nodes[node][\"SIR_p\"])\n",
    "\n",
    "print(bcolors.OKGREEN + '\\nDone.' + bcolors.ENDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WO1701FL0Qrb"
   },
   "outputs": [],
   "source": [
    "if not nodes_SIR_p_file_status:\n",
    "    path_SIR_p =  files_handler_obj.make_dir(file_info['path'], file_info['name']+' SIR_p')\n",
    "    write_layers_SIR_p_status = network_infos_writer_object.write_layers_SIR_p_to_csv(path_SIR_p, file_info['name']+\" temp SIR_p\", nodes_SIR_p)\n",
    "    if write_layers_SIR_p_status == 'Done.':\n",
    "        print(bcolors.OKGREEN + write_layers_SIR_p_status + bcolors.ENDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.HuberLoss()\n",
    "# for i, item in enumerate(model_sir):\n",
    "#     loss = loss_fn(torch.FloatTensor(real_sir[i]), torch.FloatTensor(model_sir[i]))\n",
    "#     print(f\"Layer {i + 1}: {loss.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "85SdnG9I0Qrc",
    "outputId": "67e42106-155e-4e30-80a0-24690d8ac8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "node_by_node_SIR_p_writer_status = SIR_p_file_status\n",
    "SIR_p_opened_file = None\n",
    "print(len(network_nodes_list_SIR_p.keys()))\n",
    "node_SIR_p_write_counter = 0\n",
    "nodes_SIR_p_value = {}\n",
    "if len(network_entier_nodes_list) != len(network_nodes_list_SIR_p.keys()):\n",
    "    node_counter = len(network_nodes_list_SIR_p.keys())\n",
    "    print(bcolors.FAIL + 'calculating global SIR_p:' + bcolors.ENDC)\n",
    "    with tqdm(network_entier_nodes_list, unit=\" Node\") as t_nodes:\n",
    "        for node in t_nodes:\n",
    "            if node not in network_nodes_list_SIR_p:\n",
    "                t_nodes.set_description(f\"Node {node_counter}\")\n",
    "                node_counter += 1\n",
    "                node_SIR_p = {}\n",
    "                for graph in graphs_of_network:\n",
    "                    if graph.number_of_nodes() > 0 and graph.number_of_edges() > 0 and node in graph.nodes():\n",
    "                        layer_id = graph.graph['id']\n",
    "                        node_SIR_p[layer_id] = float(graph.nodes[node]['SIR_p'])\n",
    "                node_SIR_p = {k: v for k, v in sorted(node_SIR_p.items(),key=lambda item: item[1], reverse=True)}\n",
    "                SIR_p = None\n",
    "                common_neighbors = set()\n",
    "                for i, (k_layer_id, v) in enumerate(node_SIR_p.items()):\n",
    "                    if SIR_p is None:\n",
    "                        SIR_p = v\n",
    "                        common_neighbors = set(list(graphs_of_network[k_layer_id].neighbors(node)))\n",
    "                    else:\n",
    "                        node_neighbors = set(list(graphs_of_network[k_layer_id].neighbors(node)))\n",
    "                        # node_neighborhood_effect = len(node_neighbors - common_neighbors) len(node_neighbors)\n",
    "                        node_neighborhood_effect = (len(node_neighbors) - len(node_neighbors - common_neighbors)) * (i * 0.01)\n",
    "                        common_neighbors = set.union(common_neighbors, node_neighbors)\n",
    "                        # if node_neighborhood_effect < 0.25:\n",
    "                        #     node_neighborhood_effect = 0.25\n",
    "                        SIR_p += (v - node_neighborhood_effect)\n",
    "                network_nodes_list_SIR_p[node] = SIR_p\n",
    "                nodes_SIR_p_value[node] = SIR_p\n",
    "                node_SIR_p_write_counter += 1\n",
    "                if node_SIR_p_write_counter >= 1000 or len(network_nodes_list_SIR_p.keys()) == network_entier_nodes_count:\n",
    "                    node_by_node_SIR_p_writer_status = network_infos_writer_object.node_SIR_p_writer(node_by_node_SIR_p_writer_status, SIR_p_file, nodes_SIR_p_value)\n",
    "                    nodes_SIR_p_value = {}\n",
    "                    node_SIR_p_write_counter = 0\n",
    "    network_nodes_list_SIR_p\n",
    "if not SIR_p_opened_file is None:\n",
    "    SIR_p_opened_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "wWwx0BH30Qrc"
   },
   "outputs": [],
   "source": [
    "if not SIR_p_file_status:\n",
    "    network_nodes_list_SIR_p = {k: v for k, v in sorted(network_nodes_list_SIR_p.items(),\n",
    "                                                          key=lambda item: item[1], reverse=True)}\n",
    "# network_nodes_list_SIR_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "ZkSRUc200Qrc"
   },
   "outputs": [],
   "source": [
    "if not SIR_p_file_status:\n",
    "   import pandas as pd\n",
    "   SIR_p_file_root = files_handler_obj.make_dir(file_info['path'], file_info['name'] + ' SIR_p')\n",
    "   SIR_p_file_info = SIR_p_file_root + file_info['name'] + ' SIR_p.csv'\n",
    "   (pd.DataFrame.from_dict(data=network_nodes_list_SIR_p, orient='index')\n",
    "      .to_csv(SIR_p_file_info, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_nodes_list_SIR_p = list(network_nodes_list_SIR_p.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_nodes_list_SIR_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "ML-HyWaJ0Qrd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set size: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['61', '3', '44', '8', '75']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Seed set size: {seed_set_size}\")\n",
    "i = 0\n",
    "seed_set = []\n",
    "for candidate_node, SIR_p in network_nodes_list_SIR_p:\n",
    "    if len(seed_set) < seed_set_size:\n",
    "        if i == 0:\n",
    "            seed_set.append(candidate_node)\n",
    "        else:\n",
    "            # seed_set.append(candidate_node)\n",
    "            common_neighbors_len = 0\n",
    "            node_neighbors_len = 0\n",
    "            for seed_node in seed_set:\n",
    "                for graph in graphs_of_network:\n",
    "                    if seed_node in graph and candidate_node in graph:\n",
    "                        common_neighbors_len += len(nx.common_neighbors(graph, seed_node, candidate_node))\n",
    "                        node_neighbors_len += graph.degree[candidate_node]\n",
    "            if node_neighbors_len > 0:\n",
    "                common_neighbors_percentage = common_neighbors_len / node_neighbors_len\n",
    "            else: \n",
    "                common_neighbors_percentage = 0\n",
    "            beta_scale = i * 0.01\n",
    "            if beta_scale > 0.5:\n",
    "                beta_scale = 0.5\n",
    "            candidate_node_efficient_SIR_p = float(SIR_p) - ((float(SIR_p) * common_neighbors_percentage) * beta_scale)\n",
    "            # print(SIR_p, common_neighbors_percentage, '\\n', beta_scale, candidate_node_efficient_SIR_p, '\\n')\n",
    "            if i < (len(network_nodes_list_SIR_p) - 1):\n",
    "                if candidate_node_efficient_SIR_p >= float(network_nodes_list_SIR_p[i + 1][1]):\n",
    "                    seed_set.append(candidate_node)\n",
    "            else:\n",
    "                if candidate_node_efficient_SIR_p <= 0.25:\n",
    "                    seed_set.append(candidate_node)\n",
    "    else:\n",
    "        break\n",
    "    i += 1\n",
    "    if i >= len(network_nodes_list_SIR_p):\n",
    "        for candidate_node, SIR_p in network_nodes_list_SIR_p:\n",
    "            if len(seed_set) < seed_set_size:\n",
    "                if not candidate_node in seed_set:\n",
    "                    seed_set.append(candidate_node)\n",
    "\n",
    "\n",
    "seed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "g6fBwqL40Qrr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network name: Relationshipsfromsurveys\n",
      "Seed set size: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infect scale 0.85346: 100%|\u001b[32m██████████\u001b[0m| 2000/2000 [00:26<00:00, 76.18 Iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network entier nodes count: 84\n",
      "Infected nodes count: 71.6905\n",
      "Percentage of infection: 0.8534583333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Network name: {network_name}\")\n",
    "print(f\"Seed set size: {seed_set_size}\")\n",
    "beta = 0.01\n",
    "landa = 0.7\n",
    "epoch = 2000\n",
    "SIR_diffusion_model_obj = SIR_Diffusion_Model()\n",
    "infection = SIR_diffusion_model_obj.synchronous_SIR_multilayer_with_seed_set_model(graphs_of_network, seed_set, beta, landa, epoch, network_entier_nodes_list)\n",
    "\n",
    "sir_results_infos = {}\n",
    "sir_results_infos['infection'] = infection\n",
    "sir_results_infos['percentage'] = infection / network_entier_nodes_count\n",
    "sir_results_infos['seed_set'] = seed_set\n",
    "\n",
    "network_infos_writer_object.write_results_in_file(our_model_path, f'infection k={seed_set_size} beta={beta} landa={landa} epoch={10000}', sir_results_infos)\n",
    "print(f\"Network entier nodes count: {network_entier_nodes_count}\")\n",
    "print(f\"Infected nodes count: {infection}\")\n",
    "print(f\"Percentage of infection: {sir_results_infos['percentage']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('shutdown -s')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
